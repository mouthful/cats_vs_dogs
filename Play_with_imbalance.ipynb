{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:01:07.119597Z",
     "start_time": "2020-06-03T06:01:07.115778Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import  torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms,models,datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "random.seed(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_root = '/home/hezhang/workspace/cvpr/data/training_set/'\n",
    "cats_list = os.listdir(data_root+'training_set/cats')\n",
    "interest_cats = random.sample(cats_list, int(len(cats_list)/3)) \n",
    "for item in interest_cats:\n",
    "    raw_file = data_root + 'training_set/cats/' + item\n",
    "    target_file = data_root + 'unbalance_set/cats/' + item\n",
    "    shutil.copy(raw_file, target_file)\n",
    "\n",
    "shutil.copytree(data_root+'training_set/dogs/', data_root + 'unbalance_set/dogs/')\n",
    "test_root = '/home/hezhang/workspace/cvpr/data/test_set/'\n",
    "test_cats_list = os.listdir(test_root+'test_set/cats/')\n",
    "test_dogs_list = os.listdir(test_root+'test_set/dogs/')\n",
    "new_test_cats = random.sample(test_cats_list, 500) \n",
    "new_test_dogs = random.sample(test_dogs_list, 500) \n",
    "\n",
    "for item in new_test_cats:\n",
    "    raw_file = test_root + 'test_set/cats/' + item\n",
    "    target_file = test_root + 'new_test_set/cats/' + item\n",
    "    shutil.copy(raw_file, target_file)\n",
    "    \n",
    "for item in new_test_dogs:\n",
    "    raw_file = test_root + 'test_set/dogs/' + item\n",
    "    target_file = test_root + 'new_test_set/dogs/' + item\n",
    "    shutil.copy(raw_file, target_file)\n",
    "\n",
    "train_data_dir = '/home/hezhang/workspace/cvpr/data/training_set/unbalance_set'\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(255),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(train_data_dir, transform= transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=400 ,shuffle=True)\n",
    "test_data_dir = '/home/hezhang/workspace/cvpr/data/test_set/new_test_set'\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(255),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(test_data_dir, transform= transform)\n",
    "batch_size = 40\n",
    "train_data_dir = '/home/hezhang/workspace/cvpr/data/training_set/unbalance_set'\n",
    "test_data_dir = '/home/hezhang/workspace/cvpr/data/test_set/new_test_set'\n",
    "transform = transforms.Compose([transforms.Resize(65),\n",
    "                                transforms.CenterCrop(64),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(train_data_dir, transform= transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(test_data_dir, transform= transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "class ResidualBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels,out_channels,stride=1,kernel_size=3,padding=1,bias=False):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels,out_channels,kernel_size,1,padding,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        if stride!=1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels,out_channels,kernel_size=1,stride = stride,bias=False),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential()\n",
    "\n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x += self.shortcut(residual)\n",
    "        x = nn.ReLU(inplace=True)(x)\n",
    "        return x\n",
    "        \n",
    "class ResNet34(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3,64,7,2,3,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.MaxPool2d(3,2),\n",
    "            ResidualBlock(64,64,1),\n",
    "            ResidualBlock(64,64,1),\n",
    "            ResidualBlock(64,64,1)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            ResidualBlock(64,128,1),\n",
    "            ResidualBlock(128,128,1),\n",
    "            ResidualBlock(128,128,1),\n",
    "            ResidualBlock(128,128,2)\n",
    "        )\n",
    "        \n",
    "        self.block4 = nn.Sequential(\n",
    "            ResidualBlock(128,256,1),\n",
    "            ResidualBlock(256,256,1),\n",
    "            ResidualBlock(256,256,1),\n",
    "            ResidualBlock(256,256,1),\n",
    "            ResidualBlock(256,256,1),\n",
    "            ResidualBlock(256,256,2)\n",
    "        )\n",
    "        self.block5 = nn.Sequential(\n",
    "            ResidualBlock(256,512,1),\n",
    "            ResidualBlock(512,512,1),\n",
    "            ResidualBlock(512,512,2)\n",
    "        )\n",
    "        self.avgpool = nn.AvgPool2d(2)\n",
    "        self.fc = nn.Linear(512,n_classes)\n",
    "#         self.fc = nn.Linear(256,n_classes) ## new add\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "data_root = '/home/hezhang/workspace/cvpr/data/training_set/'\n",
    "def generateTrainloader_v1(sampling='Under'):\n",
    "    temp_root = '/home/hezhang/workspace/cvpr/data/training_set/temp_set/'\n",
    "    try:\n",
    "        shutil.rmtree(temp_root+'dogs')\n",
    "        shutil.rmtree(temp_root+'cats')\n",
    "    except:\n",
    "        pass\n",
    "    if sampling == 'Under':\n",
    "        if not os.path.exists(temp_root+'dogs'):\n",
    "            os.mkdir(temp_root+'dogs')\n",
    "        ## sampling 1/3 of dogs\n",
    "        dogs_list = os.listdir(data_root+'unbalance_set/dogs')\n",
    "        interest_dogs = random.sample(dogs_list, int(len(dogs_list)/3)) \n",
    "        for item in interest_dogs:\n",
    "            raw_file = data_root + 'unbalance_set/dogs/' + item\n",
    "            target_file = data_root + 'temp_set/dogs/' + item\n",
    "            shutil.copy(raw_file, target_file)\n",
    "        shutil.copytree(data_root+'unbalance_set/cats/', data_root + 'temp_set/cats/')\n",
    "    if sampling == 'Over':\n",
    "        if not os.path.exists(temp_root+'cats'):\n",
    "            os.mkdir(temp_root+'cats')\n",
    "        ## sampling 3/1 of cats\n",
    "        cats_list = os.listdir(data_root+'unbalance_set/cats')\n",
    "        interest_cats = random.choices(cats_list, k=int(len(cats_list)*3)) \n",
    "        index = 0\n",
    "        for item in interest_cats:\n",
    "            raw_file = data_root + 'unbalance_set/cats/' + item\n",
    "            target_file = data_root + 'temp_set/cats/' + item\n",
    "            if (os.path.exists(target_file)) & (target_file[-4:]=='.jpg'):\n",
    "                target_file = target_file[:-4] + '_' + str(index) + '.jpg'\n",
    "                index += 1\n",
    "            shutil.copy(raw_file, target_file)\n",
    "        shutil.copytree(data_root+'unbalance_set/dogs/', data_root + 'temp_set/dogs/')\n",
    "    \n",
    "    train_data_dir = '/home/hezhang/workspace/cvpr/data/training_set/temp_set'\n",
    "\n",
    "    transform = transforms.Compose([transforms.Resize(65),\n",
    "                                    transforms.CenterCrop(64),\n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "    dataset = torchvision.datasets.ImageFolder(train_data_dir, transform= transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=40 ,shuffle=True)\n",
    "    \n",
    "    num_cat = 0\n",
    "    num_dog = 0\n",
    "    for item in dataset.imgs:\n",
    "        if item[1] == 0:\n",
    "            num_cat += 1\n",
    "        else:\n",
    "            num_dog += 1\n",
    "    print('generated dataset:\\nthere are {} cats,\\n{} dogs'.format(num_cat, num_dog))\n",
    "    \n",
    "    return train_loader\n",
    "\n",
    "# test_train_loader = generateTrainloader(sampling='Over')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T06:01:12.578583Z",
     "start_time": "2020-06-03T06:01:12.573592Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterian, flag, sampling='Under'):\n",
    "    losses = []\n",
    "    accs = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loader = generateTrainloader_v1(sampling=sampling)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        model.train()\n",
    "        for idx, (inputs,labels) in tqdm(enumerate(train_loader),total=len(train_loader)):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_acc += (outputs.argmax(1)==labels).float().mean().item()\n",
    "\n",
    "        test_acc = 0\n",
    "        with torch.no_grad():\n",
    "            for idx, (inputs,labels) in tqdm(enumerate(test_loader),total=len(test_loader)):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                model.eval()\n",
    "                outputs = model(inputs.float())\n",
    "                test_acc += (outputs.argmax(1)==labels).float().mean().item()\n",
    "\n",
    "        losses.append(running_loss/len(train_loader))\n",
    "        accs.append(running_acc/len(train_loader))\n",
    "        print('epochs {}/{} '.format(epoch+1,epochs))\n",
    "        print('traing_acc : {:.2f}%'.format(running_acc/len(train_loader)))\n",
    "        print('loss : {:.4f}'.format(running_loss/len(train_loader)))\n",
    "        print('test_acc : {:.2f}%'.format(test_acc/len(test_loader)))\n",
    "    torch.save(model.state_dict(), 'output/'+ flag + '.pkl')  \n",
    "        \n",
    "model = ResNet34(2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 5e-4)\n",
    "# class_weights = torch.Tensor([1.5, 0.5]).cuda() \n",
    "# criterion = nn.CrossEntropyLoss(reduce='mean',weight=class_weights)\n",
    "criterion = nn.CrossEntropyLoss(reduce='mean')\n",
    "epochs = 20\n",
    "flag = 'resnet_undersampling'\n",
    "train(model, optimizer, criterion, flag, sampling='Under')\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
    "weight_path = 'output/resnet_base.pkl'\n",
    "model = ResNet34(2).to(device)\n",
    "model.load_state_dict(torch.load(weight_path))\n",
    "test_acc = 0\n",
    "TN,FP,FN,TP = 0, 0, 0, 0\n",
    "with torch.no_grad():\n",
    "    for idx, (inputs,labels) in tqdm(enumerate(test_loader),total=len(test_loader)):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        model.eval()\n",
    "        outputs = model(inputs.float())\n",
    "#         print(outputs)\n",
    "        test_acc += (outputs.argmax(1)==labels).float().mean().item()\n",
    "        tn, fp, fn, tp = confusion_matrix(outputs.argmax(1).cpu(), labels.cpu()).ravel()\n",
    "        TN += tn\n",
    "        FP += fp\n",
    "        FN += fn\n",
    "        TP += tp\n",
    "        print(test_acc)\n",
    "        print(tn, fp, fn, tp)\n",
    "        print('--------------------****************---------------')\n",
    "print(TN, FP, FN, TP)\n",
    "print('accuracy:\\n')\n",
    "print(test_acc/len(test_loader))\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "f1_score = recall*precision/(precision+recall)\n",
    "print('metrics of dogs:\\n')\n",
    "print('precision', precision, 'recall', recall, 'f1-score', f1_score)\n",
    "TN_1 = TP\n",
    "FP_1 = FN\n",
    "FN_1 = FP\n",
    "TP_1 = TN\n",
    "precision = TP_1/(TP_1+FP_1)\n",
    "recall = TP_1/(TP_1+FN_1)\n",
    "f1_score = recall*precision/(precision+recall)\n",
    "print('metrics of cats:\\n')\n",
    "print('precision', precision, 'recall', recall, 'f1-score', f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
